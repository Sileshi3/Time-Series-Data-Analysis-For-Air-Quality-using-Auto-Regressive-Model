{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Data Analysis For Air Quality using Auto Regressive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality in Dar es Salaam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here\n",
    "import warnings \n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning) \n",
    "import inspect\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "import seaborn as sns\n",
    "from IPython.display import VimeoVideo\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "### Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: \n",
    "Connect to MongoDB server running at host \"localhost\" on port 27017. Then connect to the \"air-quality\" database and assign the collection for Dar es Salaam to the variable name dar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\",port=27017)\n",
    "db = client[\"air-quality\"]\n",
    "dar = db[\"dar-es-salaam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: \n",
    "Complete the wrangle function below so that the results from the database query are read into the DataFrame df. Be sure that the index of df is the \"timestamp\" from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(collection):\n",
    "    results = collection.find(\n",
    "        {\"metadata.site\": 29, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "    df = pd.DataFrame(results).set_index(\"timestamp\")\n",
    "    \n",
    "    df.index=df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Nairobi\")\n",
    "    \n",
    "    df=df[df[\"P2\"]<500]\n",
    "    \n",
    "    df=df[\"P2\"].resample(\"1H\").mean().fillna(method=\"ffill\").to_frame()\n",
    "    \n",
    "    df[\"P2.L1\"]=df[\"P2\"].shift(1)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:\n",
    "Use your wrangle function to read the data from the nairobi collection into the DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = wrangle(dar)\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4:\n",
    "Determine the numbers assigned to all the sensor sites in the Dar es Salaam collection. Your submission should be a list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = dar.distinct(\"metadata.site\")\n",
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: \n",
    "Determine which site in the Dar es Salaam collection has the most sensor readings (of any type, not just PM2.5 readings). You submission readings_per_site should be a list of dictionaries that follows this format:\n",
    "\n",
    "[{'_id': 6, 'count': 70360}, {'_id': 29, 'count': 131852}]\n",
    "\n",
    "Note that the values here ☝️ are from the Nairobi collection, so your values will look different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dar.aggregate(\n",
    "    [\n",
    "     {\"$group\":{\"_id\":\"$metadata.site\",\"count\":{\"$count\":{}}}}   \n",
    "    ]\n",
    ")\n",
    "readings_per_site = list(result)\n",
    "readings_per_site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n",
    "### Task 6:\n",
    "Create a wrangle function that will extract the PM2.5 readings from the site that has the most total readings in the Dar es Salaam collection. Your function should do the following steps:\n",
    "<ol>\n",
    "<li>Localize reading time stamps to the timezone for \"Africa/Dar_es_Salaam\".</li>\n",
    "<li>Remove all outlier PM2.5 readings that are above 100.</li>\n",
    "<li>Resample the data to provide the mean PM2.5 reading for each hour.</li>\n",
    "<li>Impute any missing values using the forward-will method.</li>\n",
    "<li>Return a Series y.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(collection,resample_rule=\"1H\"): \n",
    "    results = collection.find(\n",
    "        {\"metadata.site\": 11, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "        # Read results into DataFrame\n",
    "    df = pd.DataFrame(list(results)).set_index(\"timestamp\")\n",
    "    # Localize timezone\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Dar_es_Salaam\")\n",
    "    # Remove outliers\n",
    "    df = df[df[\"P2\"] < 100]\n",
    "    # Resample and forward-fill\n",
    "    y = df[\"P2\"].resample(resample_rule).mean().fillna(method=\"ffill\")\n",
    "    # Read results into DataFrame\n",
    "#     df = pd.DataFrame(list(results)).set_index(\"timestamp\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your wrangle function to query the dar collection and return your cleaned results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wrangle(dar)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Some More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: \n",
    "Create a time series plot of the readings in y. Label your x-axis \"Date\" and your y-axis \"PM2.5 Level\". Use the title \"Dar es Salaam PM2.5 Levels\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y.plot(xlabel=\"Date\",ylabel=\"PM2.5 Level\",title=\"Dar es Salaam PM2.5 Levels\",ax=ax)\n",
    "# Don't delete the code below 👇\n",
    "plt.savefig(\"images/3-5-5.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8:\n",
    "Plot the rolling average of the readings in y. Use a window size of 168 (the number of hours in a week). Label your x-axis \"Date\" and your y-axis \"PM2.5 Level\". Use the title \"Dar es Salaam PM2.5 Levels, 7-Day Rolling Average\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y.rolling(168).mean().plot(ax=ax)\n",
    "# Don't delete the code below 👇\n",
    "plt.savefig(\"images/3-5-6.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: \n",
    "Create an ACF plot for the data in y. Be sure to label the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\". Use the title \"Dar es Salaam PM2.5 Readings, ACF\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_acf(y,ax=ax)\n",
    "# Don't delete the code below 👇\n",
    "plt.savefig(\"images/3-5-7.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: \n",
    "Create an PACF plot for the data in y. Be sure to label the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\". Use the title \"Dar es Salaam PM2.5 Readings, PACF\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_pacf(y,ax=ax)\n",
    "# Don't delete the code below 👇\n",
    "plt.savefig(\"images/3-5-8.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10:\n",
    "Split y into training and test sets. The first 90% of the data should be in your training set. The remaining 10% should be in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_test = int(len(y)*0.9)\n",
    "y_train =  y.iloc[:cutoff_test]\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y.iloc[cutoff_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11:\n",
    "Establish the baseline mean absolute error for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean =y_train.mean()\n",
    "y_pred_baseline =  [y_train_mean]*len(y_train)\n",
    "mae_baseline = mean_absolute_error(y_train,y_pred_baseline)\n",
    "\n",
    "print(\"Mean P2 Reading:\", y_train_mean)\n",
    "print(\"Baseline MAE:\", mae_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: \n",
    "You're going to use an AR model to predict PM2.5 readings, but which hyperparameter settings will give you the best performance? Use a for loop to train your AR model on using settings for p from 1 to 30. Each time you train a new model, calculate its mean absolute error and append the result to the list maes. Then store your results in the Series mae_series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "p_params = range(1,3) \n",
    "maes = []\n",
    "for p in p_params: \n",
    "#     maes[p]= list() \n",
    "        # Note start time\n",
    "        # Train model\n",
    "    model = AutoReg(y_train,lags=26,old_names=False).fit()\n",
    "#         model = ARIMA(y_train).fit()\n",
    "    y_pred = model.predict().dropna()\n",
    "#     print(y_pred[1])\n",
    "            # Calculate training MAE\n",
    "#     mean_absolute_error(y_train.iloc[26:],y_pred)\n",
    "#     x=mean_absolute_error(y_train.iloc[26:],y_pred)\n",
    "    x=mean_absolute_error(y_train, y_pred_baseline)\n",
    "    maes.append(x)\n",
    "# maes.append(mean_absolute_error(y_train,y_pred_baseline))\n",
    "mae_series = pd.Series(maes, name=\"mae\", index=p_params)\n",
    "mae_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: \n",
    "Look through the results in mae_series and determine what value for p provides the best performance. Then build and train final_model using the best hyperparameter value.\n",
    "\n",
    "Note: Make sure that you build and train your model in one line of code, and that the data type of best_model is statsmodels.tsa.ar_model.AutoRegResultsWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p = ...\n",
    "best_model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14: \n",
    "Calculate the training residuals for best_model and assign the result to y_train_resid. Note that your name of your Series should be \"residuals\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resid = y_train-y_pred\n",
    "# y_train_resid.tail()\n",
    "# y_train_resid = ...\n",
    "y_train_resid.name = \"residuals\"\n",
    "y_train_resid.head()\n",
    "y_train_resid = y_train-y_pred\n",
    "# y_train_resid.tail()\n",
    "# y_train_resid = ...\n",
    "y_train_resid.name = \"residuals\"\n",
    "y_train_resid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 15: \n",
    "Create a histogram of y_train_resid. Be sure to label the x-axis as \"Residuals\" and the y-axis as \"Frequency\". Use the title \"Best Model, Training Residuals\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot histogram of residuals\n",
    "y_train_resid.plot(ax=ax)\n",
    "# Don't delete the code below 👇\n",
    "plt.savefig(\"images/3-5-14.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 16: \n",
    "Create an ACF plot for y_train_resid. Be sure to label the x-axis as \"Lag [hours]\" and y-axis as \"Correlation Coefficient\". Use the title \"Dar es Salaam, Training Residuals ACF\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_acf(y_train_resid,ax=ax);\n",
    "# Don't delete the code below 👇\n",
    "plt.savefig(\"images/3-5-15.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 17:\n",
    "Perform walk-forward validation for your model for the entire test set y_test. Store your model's predictions in the Series y_pred_wfv. Make sure the name of your Series is \"prediction\" and the name of your Series index is \"timestamp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wfv = pd.Series()\n",
    "history = y_train.copy()\n",
    "for i in range(len(y_test)):\n",
    "    model=AutoReg(history,lags=26).fit()\n",
    "    next_pred=model.forecast()\n",
    "    y_pred_wfv=y_pred_wfv.append(next_pred)\n",
    "    history=history.append(y_test[next_pred.index])\n",
    "#     pass\n",
    "y_pred_wfv.name = \"prediction\"\n",
    "y_pred_wfv.index.name = \"timestamp\"\n",
    "y_pred_wfv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 18:\n",
    "Submit your walk-forward validation predictions to the grader to see test mean absolute error for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 19: \n",
    "Put the values for y_test and y_pred_wfv into the DataFrame df_pred_test (don't forget the index). Then plot df_pred_test using plotly express. Be sure to label the x-axis as \"Date\" and the y-axis as \"PM2.5 Level\". Use the title \"Dar es Salaam, WFV Predictions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame({\"y_test\":y_test,\"y_pred_wfv\":y_pred_wfv})\n",
    "fig = fig = px.line(df_pred_test,labels={\"value\":\"PM2.5\"})\n",
    "fig.update_layout(\n",
    "    title=\"Dar es Salaam, WFV Predictions\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"PM2.5 Level\",\n",
    ")\n",
    "# Don't delete the code below 👇\n",
    "fig.write_image(\"images/3-5-18.png\", scale=1, height=500, width=700)\n",
    "​\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
